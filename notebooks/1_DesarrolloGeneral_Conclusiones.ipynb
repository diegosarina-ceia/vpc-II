{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Final Visión por Computadora 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrantes:\n",
    "\n",
    "* Marco Joel Isidro\n",
    "* Diego Sarina\n",
    "\n",
    "Profesores:\n",
    "\n",
    "* Juan Ignacio Cavalieri\n",
    "* Juan Ignacio Cornet\n",
    "* Pakdaman Seyed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">info: Debido a limitaciones de github algunos de los modelos entrenados estan alojados en [google drive](https://drive.google.com/drive/folders/1mOpRcsDtA_8p71lRvVi4ofj0fxzPjhBU?usp=sharing), además de los datasets en formato [COCO](https://drive.google.com/drive/folders/1cusBklbj8RmAGGgBtO6AiCYC581yrGcK?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema a resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto, abordamos un problema de detección de objetos en imágenes médicas centrado en la identificación de diversas enfermedades dentales. El objetivo principal es automatizar el diagnóstico visual de condiciones dentales comunes como caries, necesidad de endodoncia, o dientes impactados, a partir de imágenes médicas.\n",
    "\n",
    "El interés por resolver este problema radica en la posibilidad de asistir a los profesionales de la odontología en el diagnóstico temprano y preciso, permitiendo la intervención adecuada antes de que las patologías avancen.\n",
    "\n",
    "Para este proyecto, se utilizó un dataset proporcionado por una competencia de Kaggle, lo cual facilitó el acceso a imágenes etiquetadas de radiografías dentales con varias clases de anomalías. La detección de estas condiciones fue tratada como un problema de detección de objetos, donde el modelo debe no solo identificar la presencia de una anomalía, sino también localizar su posición en la imagen.\n",
    "\n",
    "El desafío y datasets propuesto lo pueden encontrar en el siguiente link:\n",
    "\n",
    "[Link al desafía de Kaggle](https://www.kaggle.com/datasets/truthisneverlinear/dentex-challenge-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de una imágen etiquetada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imágen etiquetada](../images/DesarrolloGeneral_Conclusiones/dataset_inicial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del datasets inicial del desafio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset utilizado para este proyecto fue inicialmente proporcionado por una competencia en Kaggle y contenía imágenes de radiografías dentales etiquetadas con tres tipos de categorías: cuadrante (donde se encontraba la anomalía), diente (identificación del diente específico afectado) y enfermedad (tipo de patología presente).\n",
    "\n",
    "Sin embargo, para nuestro propósito, que es la detección de enfermedades dentales como caries, necesidad de endodoncia o dientes impactados, las etiquetas relacionadas con los cuadrantes y los dientes específicos no eran relevantes para el problema que queríamos resolver. Por lo tanto, decidimos modificar el dataset eliminando las etiquetas de cuadrante y diente, dejando únicamente las que corresponden a las enfermedades.\n",
    "\n",
    "De esta forma, nuestro modelo se entrenará exclusivamente para identificar y localizar las anomalías dentales en las imágenes, lo que simplifica el problema y nos permite enfocarnos en el objetivo principal del proyecto: la detección automática de enfermedades dentales.\n",
    "\n",
    "A continuación, mostramos un ejemplo de la estructura propuesta en el desafío y la estructura utilizada en el proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura propuesta por Dentex\n",
    "{\n",
    "  \"images\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"width\":\n",
    "      \"height\":\n",
    "      \"file_name\":\n",
    "    }\n",
    "  ],\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"image_id\":\n",
    "      \"category_id_1\":\n",
    "      \"category_id_2\":\n",
    "      \"category_id_3\":\n",
    "      \"segmentation\":\n",
    "      \"area\":\n",
    "      \"bbox\":\n",
    "      \"iscrowd\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories_1\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories_2\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories_3\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura utilizada\n",
    "{\n",
    "  \"images\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"width\":\n",
    "      \"height\":\n",
    "      \"file_name\":\n",
    "    }\n",
    "  ],\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"image_id\":\n",
    "      \"category_id\":\n",
    "      \"segmentation\":\n",
    "      \"area\":\n",
    "      \"bbox\":\n",
    "      \"iscrowd\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para un análisis más detallado del dataset utilizado pueden acceder al notebook [EDA.ipynb](2_EDA.ipynb) en el sección \"dataset original\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeros modelos investigados y resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para abordar el problema de detección de objetos de enfermedades dentales, implementamos y entrenamos dos modelos ampliamente utilizados en tareas de detección: RetinaNet y YOLOv8. A continuación, describimos cada modelo brevemente y presentamos los resultados obtenidos en los primeros entrenamientos.\n",
    "\n",
    "RetinaNet es un modelo de detección de objetos que emplea un enfoque de red de \"una etapa\" (one-stage), lo que lo hace más rápido que otros modelos de dos etapas como Faster R-CNN. Su principal característica es la focal loss, una función de pérdida que mitiga el problema del desbalance entre clases, al darle más peso a los ejemplos difíciles (difíciles de clasificar).\n",
    "\n",
    "YOLOv8 es conocida por su velocidad y eficacia en la detección de objetos en tiempo real. YOLOv8 introduce mejoras en la arquitectura y en las técnicas de entrenamiento, lo que lo hace más eficiente que versiones anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los entrenamientos iniciales se llevaron a cabo en los notebooks [3_YOLOv8_training.ipynb](3_YOLOv8_training.ipynb) y [4_RetinaNet_training.ipynb](4_RetinaNet_training.ipynb) en sus secciones de dataset 1 o dataset original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo los entrenamientos con este dataset no mostraron buenos resultados y luego de multiples pruebas se llego a la conclusion de que era problema del etiquetado del dataset. A continuación se resumen los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### YOLOv8:\n",
    "\n",
    "```\n",
    "Model Summary (fused):\n",
    "- **Layers**: 186\n",
    "- **Parameters**: 2,685,148\n",
    "- **Gradients**: 0\n",
    "- **GFLOPs**: 6.8\n",
    "\n",
    "| Class                  | Images | Instances | Box(P) | R    | mAP50 | mAP50-95 |\n",
    "|------------------------|--------|-----------|--------|------|-------|----------|\n",
    "| **all**                | 151    | 709       | 0.467  | 0.564| 0.497 | 0.321    |\n",
    "| **Caries**             | 128    | 447       | 0.351  | 0.620| 0.404 | 0.292    |\n",
    "| **Deep Caries**        | 69     | 126       | 0.464  | 0.579| 0.557 | 0.354    |\n",
    "| **Impacted**           | 48     | 106       | 0.677  | 0.991| 0.956 | 0.604    |\n",
    "| **Periapical Lesion**  | 23     | 30        | 0.377  | 0.067| 0.071 | 0.034    |\n",
    "\n",
    "```\n",
    "\n",
    "Después de entrenar nuestro modelo YOLO para la detección de condiciones dentales, obtuvimos algunos resultados interesantes. Vamos a analizarlos:\n",
    "\n",
    "1. Rendimiento general:\n",
    "Nuestro modelo alcanzó un mAP50 de 0.497, lo que significa que está detectando objetos con una precisión media del 49.7% cuando consideramos un umbral de IoU del 50%. No está mal, pero definitivamente hay espacio para mejorar.\n",
    "\n",
    "2. Precisión y Recall:\n",
    "Obtuvimos una precisión de 0.467 y un recall de 0.564. En términos simples, esto sugiere que nuestro modelo es un poco mejor encontrando condiciones dentales reales (recall) que evitando falsos positivos (precisión).\n",
    "\n",
    "3. Configuración del entrenamiento:\n",
    "Usamos dropout de 0.3, lo cual probablemente ayudó a prevenir el overfitting, especialmente considerando que nuestro dataset no es muy grande.ç\n",
    "\n",
    "4. Áreas de mejora:\n",
    "\n",
    "- Definitivamente necesitamos más imágenes, sobre todo para las clases que el modelo tiene más dificultad en detectar.\n",
    "- Podríamos experimentar con diferentes técnicas de aumento de datos.\n",
    "- Tal vez valdría la pena probar otras arquitecturas de modelos o pesos pre-entrenados diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetinaNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.452\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.447\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
    "\n",
    "Evaluation results for bbox: \n",
    "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
    "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
    "| 25.705 | 45.206 | 25.807 |  nan  |  nan  | 25.705 |\n",
    "\n",
    "Per-category bbox AP: \n",
    "| category          | AP     | category    | AP     | category   | AP     |\n",
    "|:------------------|:-------|:------------|:-------|:-----------|:-------|\n",
    "| Caries            | 23.356 | Deep Caries | 23.605 | Impacted   | 49.093 |\n",
    "| Periapical Lesion | 6.765  |             |        |            |        |\n",
    "```\n",
    "\n",
    "*Baja precisión general:* El modelo tiene un AP global de 0.257 y solo alcanza un AP50 de 0.452, lo que indica que las detecciones son inexactas, especialmente cuando se requiere mayor precisión en la localización de las enfermedades.\n",
    "\n",
    "*Rendimiento desigual entre categorías:* El modelo identifica mejor los dientes impactados (AP de 49.09%), pero tiene serias dificultades con otras categorías, como Periapical Lesion, donde el AP es muy bajo (6.77%).\n",
    "\n",
    "*Problemas de detección y localización:* El bajo recall sugiere que el modelo está fallando en detectar muchas anomalías, y la falta de precisión en las cajas delimitadoras podría estar afectada por un desbalance en las clases y un dataset subóptimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problematica encontrada y resolución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los principales desafíos que enfrentamos durante el desarrollo del proyecto fue descubrir que el dataset estaba mal etiquetado. Este problema afectaba directamente el rendimiento de los modelos, ya que muchas imágenes tenían etiquetas que se aplicaban al diente en su totalidad, en lugar de centrarse en la patología específica presente. Esto generaba confusión durante el entrenamiento, lo que resultaba en una baja precisión en las predicciones.\n",
    "\n",
    "Al analizar en detalle las etiquetas del dataset, encontramos varios tipos de errores:\n",
    "\n",
    "Etiquetas superpuestas: Debido a que se etiquetaba el diente completo, en muchas imágenes había etiquetas de diferentes categorías solapadas, dificultando la identificación clara de cada patología.\n",
    "Cajas mal posicionadas: Las cajas delimitadoras (bounding boxes) frecuentemente no coincidían con las áreas donde se encontraban las anomalías, afectando la capacidad del modelo para localizar las enfermedades de forma precisa.\n",
    "A continuación, mostramos ejemplos visuales de imágenes mal etiquetadas, donde se puede observar la discrepancia entre las cajas de detección y las enfermedades presentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiples dientes etiquetados con una sola etiqueta.\n",
    "\n",
    "![Error1](../images/DesarrolloGeneral_Conclusiones/error_1.jpg)\n",
    "\n",
    "Etiquetas superpuestas de diferentes categorías.\n",
    "\n",
    "![Error2](../images/DesarrolloGeneral_Conclusiones/error_2.jpg)\n",
    "\n",
    "Etiquetas superpuestas de la misma categoría y bbox demasiado grandes.\n",
    "\n",
    "![Error3](../images/DesarrolloGeneral_Conclusiones/error_3.jpg)\n",
    "\n",
    "Etiquetas mal puestas.\n",
    "\n",
    "![Error4](../images/DesarrolloGeneral_Conclusiones/error_4.png)\n",
    "\n",
    "Etiquetas mal puestas y superpuestas.\n",
    "\n",
    "![Error5](../images/DesarrolloGeneral_Conclusiones/error_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver este problema, decidimos utilizar una versión revisada del dataset, basada en el trabajo de otro participante del desafío, quien había corregido algunos de los problemas de etiquetado. Esta versión tenía etiquetas más consistentes y precisas, enfocándose en la detección de las patologías en lugar de en el diente completo.\n",
    "\n",
    "Sin embargo, esta versión del dataset no incluía la categoría de diente impactado, una anomalía que queríamos seguir detectando en nuestro proyecto. Por lo tanto, añadimos manualmente la categoría de diente impactado a la nueva versión del dataset, asegurándonos de que las etiquetas y las cajas delimitadoras fueran correctas.\n",
    "\n",
    "La corrección del dataset fue un paso crucial, ya que permitió mejorar significativamente el rendimiento de los modelos al eliminar gran parte de la confusión generada por las etiquetas incorrectas. La calidad de los datos es fundamental para que los modelos de detección de objetos puedan aprender patrones útiles y producir predicciones precisas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos investigados y resultados principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que corregimos el dataset, realizamos nuevos entrenamientos de los modelos YOLOv8 y RetinaNet. Para mejorar el rendimiento, aplicamos varias técnicas de aumento de datos utilizando Roboflow, que incluyeron:\n",
    "\n",
    "![Error5](../images/DesarrolloGeneral_Conclusiones/augmentation.jpg)\n",
    "\n",
    "Estas técnicas nos permitieron aumentar la diversidad del dataset, mejorando la capacidad de generalización de los modelos al presentarles variaciones de las imágenes originales. Se destaca principalmente el uso de la modificación del contrastre, lo cual es algo comun debido a que distintas máquinas de radiagrafías generan las placas con diferentes contrastes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados de YOLOv8\n",
    "\n",
    "En el desarrollo del notebook [3_YOLOv8_training.ipynb](3_YOLOv8_training.ipynb) se encuentran disponibles todos los resultados parciales obtenidos para cada dataset probado.\n",
    "\n",
    "En esta sección, nos enfocaremos en analizar los resultados obtenidos utilizando un nuevo dataset corregido. En el primer entrenamiento, se utilizó el dataset corregido sin aplicar técnicas de aumento de datos (data augmentation) y con los pesos preentrenados. Esto permitió establecer una línea base (baseline) para el modelo, reflejando la necesidad de aumentar los datos para mejorar su desempeño.\n",
    "\n",
    "En el segundo entrenamiento, se aplicaron técnicas de aumento de datos al dataset. Los resultados obtenidos mostraron una mejora significativa, destacando:\n",
    "\n",
    "* **Reducción del tiempo de convergencia del modelo:** El modelo logró ajustar sus parámetros más rápidamente.\n",
    "* **Mejora en las métricas de Recall y mAP50:** Se observaron incrementos en estas métricas, indicando una mayor capacidad del modelo para identificar correctamente las clases de interés.\n",
    "\n",
    "#### Comparación de pérdidas durante el entrenamiento\n",
    "\n",
    "![train_yolo](../images/DesarrolloGeneral_Conclusiones/yolo_train_loss.png)\n",
    "\n",
    "En la gráfica, se puede observar que el entrenamiento con data augmentation presenta una reducción más rápida de la pérdida (loss), lo cual sugiere que el modelo se beneficia de la mayor variedad de ejemplos proporcionados. Esto se traduce en un ajuste más eficaz de los parámetros del modelo.\n",
    "\n",
    "#### Estabilización de mAP50\n",
    "\n",
    "La siguiente gráfica muestra cómo el mAP50 alcanza un mayor grado de estabilidad cuando se utiliza el dataset aumentado, lo que sugiere un mejor rendimiento en términos de precisión:\n",
    "\n",
    "![train_yolo_map50](../images/DesarrolloGeneral_Conclusiones/yolo_map50.png)\n",
    "\n",
    "#### Comparación entre ambos modelos\n",
    "\n",
    "A continuación, se presenta una tabla comparativa que resume las métricas clave obtenidas durante ambos entrenamientos:\n",
    "\n",
    "| Métrica                | Primer Entrenamiento | Segundo Entrenamiento |\n",
    "|------------------------|----------------------|-----------------------|\n",
    "| Parameters             | 2,685,343            | 2,685,343             |\n",
    "| **all** - mAP50        | 0.838                | 0.865                 |\n",
    "| **all** - mAP50-95     | 0.542                | 0.549                 |\n",
    "| **caries** - mAP50     | 0.508                | 0.587                 |\n",
    "| **corona** - mAP50     | 0.973                | 0.978                 |\n",
    "| **diente impactado** - mAP50  | 0.835        | 0.855                 |\n",
    "| **endodoncia** - mAP50  | 0.877               | 0.910                 |\n",
    "| **implante** - mAP50    | 0.995               | 0.995                 |\n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "Los resultados demuestran que la incorporación de data augmentation no solo mejora el rendimiento del modelo, sino que también ayuda a obtener una mayor estabilidad en las métricas de precisión (mAP50). Esto es particularmente relevante para un modelo como YOLOv8, que se beneficia de una mayor diversidad en los datos de entrenamiento para aprender patrones más robustos.\n",
    "\n",
    "En resumen, el uso del dataset aumentado permitió obtener mejores resultados en términos de precisión y capacidad de detección, lo que resalta la importancia de trabajar con datasets enriquecidos y de calidad en el proceso de entrenamiento de modelos de detección de objetos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados de RetinaNet\n",
    "\n",
    "Realizamos dos entrenamientos del modelo RetinaNet utilizando el nuevo dataset corregido:\n",
    "\n",
    "En el primer caso se utilizó el dataset corregido sin aplicar técnicas de aumento de datos y sin pesos preentrenados. Este entrenamiento sirvió como punto de partida, pero las métricas de rendimiento iniciales fueron limitadas, lo que reflejó la necesidad de mejorar la calidad del entrenamiento.\n",
    "\n",
    "En el segundo entrenamiento, se implementaron dos mejoras clave:\n",
    "\n",
    "* Aumento de datos: Se aplicaron técnicas como flip, rotaciones y modificaciones de contraste, lo que aumentó la diversidad del dataset y mejoró la capacidad de generalización del modelo.\n",
    "* Pesos preentrenados: La inclusión de pesos preentrenados aceleró el proceso de aprendizaje, permitiendo que el modelo se ajustara más rápidamente a los datos.\n",
    "Comparación de Resultados\n",
    "\n",
    "Comparación de perdidas durante el entrenamiento.\n",
    "\n",
    "![train_retina](../images/DesarrolloGeneral_Conclusiones/train_retina.png)\n",
    "\n",
    "En la gráfica, se puede observar que el segundo entrenamiento fue más estable y mejoró más rápidamente desde el inicio. Además, los resultados en términos de precisión mostraron una notable mejora. En particular, el AP50 del segundo modelo fue significativamente superior al del primero, lo que indica que la capacidad del modelo para detectar correctamente las patologías dentales fue mucho más efectiva.\n",
    "\n",
    "Métricas Clave de RetinaNet\n",
    "\n",
    "| Métrica                 | Primer Entrenamiento | Segundo Entrenamiento |\n",
    "|-------------------------|----------------------|-----------------------|\n",
    "| AP-caries               | 28.81                | 33.71                 |\n",
    "| AP-corona               | 57.05                | 57.85                 |\n",
    "| AP-diente impactado     | 56.40                | 54.83                 |\n",
    "| AP-endodoncia           | 36.65                | 44.49                 |\n",
    "| AP-implante             | 42.19                | 58.55                 |\n",
    "| mAP50                   | 78.49                | 85.69                 |\n",
    "| mAP75                   | 48.19                | 48.49                 |\n",
    "| Iteraciones             | 2000                 | 2000                  |\n",
    "\n",
    "\n",
    "Estas mejoras resaltan la importancia del aumento de datos y la utilización de pesos preentrenados en el entrenamiento de modelos de detección de objetos, lo que permitió obtener resultados más precisos y confiables en la detección de enfermedades dentales.\n",
    "\n",
    "Además como se puede observar el modelo entrenado sin aumento de datos al final tuvo una menor perdida de entrenamiento, lo que junto con que obtuvo peores metricas, da a entendar que al modelo le esta faltando generalización. Lo cual se resolvio en parte con las tecnicas de aumento de datos aplicadas sobre el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con Faster R-CNN\n",
    "\n",
    "Además de los entrenamientos con YOLOv8 y RetinaNet, también realizamos una prueba con Faster R-CNN. Sin embargo, encontramos que la falta de suficientes épocas de entrenamiento debido a limitaciones de tiempo y capacidades de procesamiento, resultó en un rendimiento insatisfactorio. Las métricas obtenidas para Faster R-CNN fueron considerablemente inferiores a las de YOLOv8 y RetinaNet, lo que subraya la importancia de un entrenamiento adecuado y del ajuste de los hiperparámetros.\n",
    "\n",
    " ```\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.603\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.339\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.380\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.152\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.294\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
    " ```\n",
    "\n",
    "En base a las curvas de entrenamiento, se puede observar que el modelo esta overfitiando aunque se aplicaron técnicas de regulación como Weight Decay (L2 Regularization).\n",
    "\n",
    "Perdida de entrenamiento.\n",
    "\n",
    "![train_faster](../images/DesarrolloGeneral_Conclusiones/train_faster.png)\n",
    "\n",
    "Perdida de validación.\n",
    "\n",
    "![val_faster](../images/DesarrolloGeneral_Conclusiones/val_faster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lo largo del desarrollo de este practico, hemos enfrentado diversos desafíos que nos han permitido profundizar nuestra comprensión de la aplicación práctica de modelos de aprendizaje profundo en el campo de la odontología. Las conclusiones extraídas de este trabajo resaltan los logros alcanzados y también las oportunidades de mejoras en esta área. A continuación, se presentan los principales hallazgos y reflexiones:\n",
    "\n",
    "1. **Importancia de la Calidad de los Datos:**\n",
    "   El proyecto demostró claramente la crucial importancia de contar con un dataset correctamente etiquetado. Los errores iniciales en el etiquetado afectaron significativamente el rendimiento de los modelos, subrayando la necesidad de una cuidadosa preparación y validación de los datos antes del entrenamiento.\n",
    "\n",
    "2. **Eficacia de las Técnicas de Aumento de Datos:**\n",
    "   La aplicación de técnicas de aumento de datos, como flips horizontales y verticales, rotaciones y modificaciones de contraste, resultó en mejoras sustanciales en el rendimiento de los modelos. Esto se evidenció particularmente en YOLOv8 y RetinaNet, donde se observaron incrementos significativos en métricas clave como mAP50 y AP.\n",
    "\n",
    "3. **Superioridad de YOLOv8 y RetinaNet:**\n",
    "   Entre los modelos evaluados, YOLOv8 y RetinaNet demostraron ser los más efectivos para la tarea de detección de enfermedades dentales. YOLOv8 destacó por su rápida convergencia y altos valores de mAP50, mientras que RetinaNet mostró mejoras significativas con el uso de pesos preentrenados y aumento de datos.\n",
    "\n",
    "4. **Limitaciones de Faster R-CNN:**\n",
    "   El rendimiento inferior de Faster R-CNN en comparación con YOLOv8 y RetinaNet subraya la importancia de ajustar adecuadamente los hiperparámetros y proporcionar suficiente tiempo de entrenamiento. También destaca cómo diferentes arquitecturas pueden requerir enfoques distintos para optimizar su rendimiento en tareas específicas.\n",
    "\n",
    "5. **Desafíos en la Detección de Clases Específicas:**\n",
    "   Se observaron variaciones en el rendimiento entre diferentes clases de enfermedades dentales. Por ejemplo, tanto YOLOv8 como RetinaNet mostraron un rendimiento particularmente alto en la detección de implantes y coronas, mientras que la detección de caries resultó más desafiante. Esto sugiere la necesidad de estrategias específicas para mejorar la detección de clases problemáticas.\n",
    "\n",
    "6. **Importancia de la Evaluación Comparativa:**\n",
    "   La comparación sistemática entre diferentes modelos y configuraciones de entrenamiento proporcionó insights valiosos sobre las fortalezas y debilidades de cada enfoque. Esto refuerza la importancia de realizar evaluaciones comparativas exhaustivas en proyectos de visión por computadora.\n",
    "\n",
    "7. **Potencial para Aplicaciones Prácticas:**\n",
    "   Los resultados prometedores, especialmente de YOLOv8 y RetinaNet, sugieren que estos modelos tienen un potencial significativo para su aplicación en entornos clínicos reales, donde podrían asistir a los profesionales dentales en la detección temprana y precisa de diversas condiciones dentales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpc-ii-2tCthqWZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
