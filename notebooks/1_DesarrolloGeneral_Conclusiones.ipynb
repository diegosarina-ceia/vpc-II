{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Final Visión por Computadora 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrantes:\n",
    "\n",
    "* Marco Joel Isidro\n",
    "* Diego Sarina\n",
    "\n",
    "Profesores:\n",
    "\n",
    "* Juan Ignacio Cavalieri\n",
    "* Juan Ignacio Cornet\n",
    "* Pakdaman Seyed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">info: Debido a limitaciones de github algunos de los modelos entrenados estan alojados en [google drive](https://drive.google.com/drive/folders/1mOpRcsDtA_8p71lRvVi4ofj0fxzPjhBU?usp=sharing), además de los datasets en formato [COCO](https://drive.google.com/drive/folders/1cusBklbj8RmAGGgBtO6AiCYC581yrGcK?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema a resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto, abordamos un problema de detección de objetos en imágenes médicas centrado en la identificación de diversas enfermedades dentales. El objetivo principal es automatizar el diagnóstico visual de condiciones dentales comunes como caries, necesidad de endodoncia, o dientes impactados, a partir de imágenes médicas.\n",
    "\n",
    "El interés por resolver este problema radica en la posibilidad de asistir a los profesionales de la odontología en el diagnóstico temprano y preciso, permitiendo la intervención adecuada antes de que las patologías avancen.\n",
    "\n",
    "Para este proyecto, se utilizó un dataset proporcionado por una competencia de Kaggle, lo cual facilitó el acceso a imágenes etiquetadas de radiografías dentales con varias clases de anomalías. La detección de estas condiciones fue tratada como un problema de detección de objetos, donde el modelo debe no solo identificar la presencia de una anomalía, sino también localizar su posición en la imagen.\n",
    "\n",
    "El desafío y datasets propuesto lo pueden encontrar en el siguiente link:\n",
    "\n",
    "[Link al desafía de Kaggle](https://www.kaggle.com/datasets/truthisneverlinear/dentex-challenge-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de una imágen etiquetada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imágen etiquetada](../images/DesarrolloGeneral_Conclusiones/dataset_inicial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del datasets inicial del desafio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset utilizado para este proyecto fue inicialmente proporcionado por una competencia en Kaggle y contenía imágenes de radiografías dentales etiquetadas con tres tipos de categorías: cuadrante (donde se encontraba la anomalía), diente (identificación del diente específico afectado) y enfermedad (tipo de patología presente).\n",
    "\n",
    "Sin embargo, para nuestro propósito, que es la detección de enfermedades dentales como caries, necesidad de endodoncia o dientes impactados, las etiquetas relacionadas con los cuadrantes y los dientes específicos no eran relevantes para el problema que queríamos resolver. Por lo tanto, decidimos modificar el dataset eliminando las etiquetas de cuadrante y diente, dejando únicamente las que corresponden a las enfermedades.\n",
    "\n",
    "De esta forma, nuestro modelo se entrenará exclusivamente para identificar y localizar las anomalías dentales en las imágenes, lo que simplifica el problema y nos permite enfocarnos en el objetivo principal del proyecto: la detección automática de enfermedades dentales.\n",
    "\n",
    "A continuación, mostramos un ejemplo de la estructura propuesta en el desafío y la estructura utilizada en el proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura propuesta por Dentex\n",
    "{\n",
    "  \"images\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"width\":\n",
    "      \"height\":\n",
    "      \"file_name\":\n",
    "    }\n",
    "  ],\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"image_id\":\n",
    "      \"category_id_1\":\n",
    "      \"category_id_2\":\n",
    "      \"category_id_3\":\n",
    "      \"segmentation\":\n",
    "      \"area\":\n",
    "      \"bbox\":\n",
    "      \"iscrowd\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories_1\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories_2\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories_3\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura utilizada\n",
    "{\n",
    "  \"images\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"width\":\n",
    "      \"height\":\n",
    "      \"file_name\":\n",
    "    }\n",
    "  ],\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"image_id\":\n",
    "      \"category_id\":\n",
    "      \"segmentation\":\n",
    "      \"area\":\n",
    "      \"bbox\":\n",
    "      \"iscrowd\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para un análisis más detallado del dataset utilizado pueden acceder al notebook [EDA.ipynb](2_EDA.ipynb) en el sección \"dataset original\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeros modelos investigados y resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para abordar el problema de detección de objetos de enfermedades dentales, implementamos y entrenamos dos modelos ampliamente utilizados en tareas de detección: RetinaNet y YOLOv8. A continuación, describimos cada modelo brevemente y presentamos los resultados obtenidos en los primeros entrenamientos.\n",
    "\n",
    "RetinaNet es un modelo de detección de objetos que emplea un enfoque de red de \"una etapa\" (one-stage), lo que lo hace más rápido que otros modelos de dos etapas como Faster R-CNN. Su principal característica es la focal loss, una función de pérdida que mitiga el problema del desbalance entre clases, al darle más peso a los ejemplos difíciles (difíciles de clasificar).\n",
    "\n",
    "YOLOv8 es conocida por su velocidad y eficacia en la detección de objetos en tiempo real. YOLOv8 introduce mejoras en la arquitectura y en las técnicas de entrenamiento, lo que lo hace más eficiente que versiones anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los entrenamientos iniciales se llevaron a cabo en los notebooks [3_YOLOv8_training.ipynb](3_YOLOv8_training.ipynb) y [4_RetinaNet_training.ipynb](4_RetinaNet_training.ipynb) en sus secciones de dataset 1 o dataset original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo los entrenamientos con este dataset no mostraron buenos resultados y luego de multiples pruebas se llego a la conclusion de que era problema del etiquetado del dataset. A continuación se resumen los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### YOLOv8:\n",
    "\n",
    "```\n",
    "Model Summary (fused):\n",
    "- **Layers**: 186\n",
    "- **Parameters**: 2,685,148\n",
    "- **Gradients**: 0\n",
    "- **GFLOPs**: 6.8\n",
    "\n",
    "| Class                  | Images | Instances | Box(P) | R    | mAP50 | mAP50-95 |\n",
    "|------------------------|--------|-----------|--------|------|-------|----------|\n",
    "| **all**                | 151    | 709       | 0.467  | 0.564| 0.497 | 0.321    |\n",
    "| **Caries**             | 128    | 447       | 0.351  | 0.620| 0.404 | 0.292    |\n",
    "| **Deep Caries**        | 69     | 126       | 0.464  | 0.579| 0.557 | 0.354    |\n",
    "| **Impacted**           | 48     | 106       | 0.677  | 0.991| 0.956 | 0.604    |\n",
    "| **Periapical Lesion**  | 23     | 30        | 0.377  | 0.067| 0.071 | 0.034    |\n",
    "\n",
    "```\n",
    "\n",
    "Después de entrenar nuestro modelo YOLO para la detección de condiciones dentales, obtuvimos algunos resultados interesantes. Vamos a analizarlos:\n",
    "\n",
    "1. Rendimiento general:\n",
    "Nuestro modelo alcanzó un mAP50 de 0.497, lo que significa que está detectando objetos con una precisión media del 49.7% cuando consideramos un umbral de IoU del 50%. No está mal, pero definitivamente hay espacio para mejorar.\n",
    "\n",
    "2. Precisión y Recall:\n",
    "Obtuvimos una precisión de 0.467 y un recall de 0.564. En términos simples, esto sugiere que nuestro modelo es un poco mejor encontrando condiciones dentales reales (recall) que evitando falsos positivos (precisión).\n",
    "\n",
    "3. Configuración del entrenamiento:\n",
    "Usamos dropout de 0.3, lo cual probablemente ayudó a prevenir el overfitting, especialmente considerando que nuestro dataset no es muy grande.ç\n",
    "\n",
    "4. Áreas de mejora:\n",
    "\n",
    "- Definitivamente necesitamos más imágenes, sobre todo para las clases que el modelo tiene más dificultad en detectar.\n",
    "- Podríamos experimentar con diferentes técnicas de aumento de datos.\n",
    "- Tal vez valdría la pena probar otras arquitecturas de modelos o pesos pre-entrenados diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetinaNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.452\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.447\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
    "\n",
    "Evaluation results for bbox: \n",
    "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
    "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
    "| 25.705 | 45.206 | 25.807 |  nan  |  nan  | 25.705 |\n",
    "\n",
    "Per-category bbox AP: \n",
    "| category          | AP     | category    | AP     | category   | AP     |\n",
    "|:------------------|:-------|:------------|:-------|:-----------|:-------|\n",
    "| Caries            | 23.356 | Deep Caries | 23.605 | Impacted   | 49.093 |\n",
    "| Periapical Lesion | 6.765  |             |        |            |        |\n",
    "```\n",
    "\n",
    "*Baja precisión general:* El modelo tiene un AP global de 0.257 y solo alcanza un AP50 de 0.452, lo que indica que las detecciones son inexactas, especialmente cuando se requiere mayor precisión en la localización de las enfermedades.\n",
    "\n",
    "*Rendimiento desigual entre categorías:* El modelo identifica mejor los dientes impactados (AP de 49.09%), pero tiene serias dificultades con otras categorías, como Periapical Lesion, donde el AP es muy bajo (6.77%).\n",
    "\n",
    "*Problemas de detección y localización:* El bajo recall sugiere que el modelo está fallando en detectar muchas anomalías, y la falta de precisión en las cajas delimitadoras podría estar afectada por un desbalance en las clases y un dataset subóptimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problematica encontrada y resolución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los principales desafíos que enfrentamos durante el desarrollo del proyecto fue descubrir que el dataset estaba mal etiquetado. Este problema afectaba directamente el rendimiento de los modelos, ya que muchas imágenes tenían etiquetas que se aplicaban al diente en su totalidad, en lugar de centrarse en la patología específica presente. Esto generaba confusión durante el entrenamiento, lo que resultaba en una baja precisión en las predicciones.\n",
    "\n",
    "Al analizar en detalle las etiquetas del dataset, encontramos varios tipos de errores:\n",
    "\n",
    "Etiquetas superpuestas: Debido a que se etiquetaba el diente completo, en muchas imágenes había etiquetas de diferentes categorías solapadas, dificultando la identificación clara de cada patología.\n",
    "Cajas mal posicionadas: Las cajas delimitadoras (bounding boxes) frecuentemente no coincidían con las áreas donde se encontraban las anomalías, afectando la capacidad del modelo para localizar las enfermedades de forma precisa.\n",
    "A continuación, mostramos ejemplos visuales de imágenes mal etiquetadas, donde se puede observar la discrepancia entre las cajas de detección y las enfermedades presentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiples dientes etiquetados con una sola etiqueta.\n",
    "\n",
    "![Error1](../images/DesarrolloGeneral_Conclusiones/error_1.jpg)\n",
    "\n",
    "Etiquetas superpuestas de diferentes categorías.\n",
    "\n",
    "![Error2](../images/DesarrolloGeneral_Conclusiones/error_2.jpg)\n",
    "\n",
    "Etiquetas superpuestas de la misma categoría y bbox demasiado grandes.\n",
    "\n",
    "![Error3](../images/DesarrolloGeneral_Conclusiones/error_3.jpg)\n",
    "\n",
    "Etiquetas mal puestas.\n",
    "\n",
    "![Error4](../images/DesarrolloGeneral_Conclusiones/error_4.png)\n",
    "\n",
    "Etiquetas mal puestas y superpuestas.\n",
    "\n",
    "![Error5](../images/DesarrolloGeneral_Conclusiones/error_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver este problema, decidimos utilizar una versión revisada del dataset, basada en el trabajo de otro participante del desafío, quien había corregido algunos de los problemas de etiquetado. Esta versión tenía etiquetas más consistentes y precisas, enfocándose en la detección de las patologías en lugar de en el diente completo.\n",
    "\n",
    "Sin embargo, esta versión del dataset no incluía la categoría de diente impactado, una anomalía que queríamos seguir detectando en nuestro proyecto. Por lo tanto, añadimos manualmente la categoría de diente impactado a la nueva versión del dataset, asegurándonos de que las etiquetas y las cajas delimitadoras fueran correctas.\n",
    "\n",
    "La corrección del dataset fue un paso crucial, ya que permitió mejorar significativamente el rendimiento de los modelos al eliminar gran parte de la confusión generada por las etiquetas incorrectas. La calidad de los datos es fundamental para que los modelos de detección de objetos puedan aprender patrones útiles y producir predicciones precisas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos investigados y resultados principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que corregimos el dataset, realizamos nuevos entrenamientos de los modelos YOLOv8 y RetinaNet. Para mejorar el rendimiento, aplicamos varias técnicas de aumento de datos utilizando Roboflow, que incluyeron:\n",
    "\n",
    "* Flip horizontal y vertical\n",
    "* Rotaciones de las imágenes\n",
    "* Modificaciones de contraste\n",
    "\n",
    "Estas técnicas nos permitieron aumentar la diversidad del dataset, mejorando la capacidad de generalización de los modelos al presentarles variaciones de las imágenes originales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados de YOLOv8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados de RetinaNet\n",
    "\n",
    "Realizamos dos entrenamientos del modelo RetinaNet utilizando el nuevo dataset corregido:\n",
    "\n",
    "En el primer caso se utilizó el dataset corregido sin aplicar técnicas de aumento de datos y sin pesos preentrenados. Este entrenamiento sirvió como punto de partida, pero las métricas de rendimiento iniciales fueron limitadas, lo que reflejó la necesidad de mejorar la calidad del entrenamiento.\n",
    "\n",
    "En el segundo entrenamiento, se implementaron dos mejoras clave:\n",
    "\n",
    "* Aumento de datos: Se aplicaron técnicas como flip, rotaciones y modificaciones de contraste, lo que aumentó la diversidad del dataset y mejoró la capacidad de generalización del modelo.\n",
    "* Pesos preentrenados: La inclusión de pesos preentrenados aceleró el proceso de aprendizaje, permitiendo que el modelo se ajustara más rápidamente a los datos.\n",
    "Comparación de Resultados\n",
    "\n",
    "Comparación de perdidas durante el entrenamiento.\n",
    "\n",
    "![train_retina](../images/DesarrolloGeneral_Conclusiones/train_retina.png)\n",
    "\n",
    "En la gráfica, se puede observar que el segundo entrenamiento fue más estable y mejoró más rápidamente desde el inicio. Además, los resultados en términos de precisión mostraron una notable mejora. En particular, el AP50 del segundo modelo fue significativamente superior al del primero, lo que indica que la capacidad del modelo para detectar correctamente las patologías dentales fue mucho más efectiva.\n",
    "\n",
    "Métricas Clave de RetinaNet\n",
    "\n",
    "| Métrica                 | Primer Entrenamiento | Segundo Entrenamiento |\n",
    "|-------------------------|----------------------|-----------------------|\n",
    "| AP                      | 44.22                | 49.88                 |\n",
    "| AP-caries               | 28.81                | 33.71                 |\n",
    "| AP-corona               | 57.05                | 57.85                 |\n",
    "| AP-diente impactado     | 56.40                | 54.83                 |\n",
    "| AP-endodoncia           | 36.65                | 44.49                 |\n",
    "| AP-implante             | 42.19                | 58.55                 |\n",
    "| AP50                    | 78.49                | 85.69                 |\n",
    "| AP75                    | 48.19                | 48.49                 |\n",
    "| APl                     | 45.20                | 55.57                 |\n",
    "| APm                     | 24.32                | 42.24                 |\n",
    "| APs                     | NaN                  | NaN                   |\n",
    "| Iteraciones             | 2000                 | 2000                  |\n",
    "\n",
    "\n",
    "Estas mejoras resaltan la importancia del aumento de datos y la utilización de pesos preentrenados en el entrenamiento de modelos de detección de objetos, lo que permitió obtener resultados más precisos y confiables en la detección de enfermedades dentales.\n",
    "\n",
    "Además como se puede observar el modelo entrenado sin aumento de datos al final tuvo una menor perdida de entrenamiento, lo quejunto con que obtuvo peores metricas, da a entendar que al modelo le esta faltando generalización. Lo cual se resolvio en parte con las tecnicas de aumento de datos aplicadas sobre el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba con Faster R-CNN\n",
    "\n",
    "Además de los entrenamientos con YOLOv8 y RetinaNet, también realizamos una prueba con Faster R-CNN. Sin embargo, encontramos que mantener el tamaño de los objetos consistente en todas las imágenes, junto con la falta de suficientes épocas de entrenamiento debido a limitaciones de tiempo de procesamiento, resultó en un rendimiento insatisfactorio. Las métricas obtenidas para Faster R-CNN fueron considerablemente inferiores a las de YOLOv8 y RetinaNet, lo que subraya la importancia de un entrenamiento adecuado y del ajuste de los hiperparámetros.\n",
    "\n",
    " ```\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.603\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.339\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.226\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.380\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.152\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.417\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.294\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.483\n",
    " ```\n",
    "\n",
    "En base a las curvas de entrenamiento, se puede observar que el modelo esta overfitiando aunque se aplicaron técnicas de regulación como Weight Decay (L2 Regularization).\n",
    "\n",
    "Perdida de entrenamiento.\n",
    "\n",
    "![train_faster](../images/DesarrolloGeneral_Conclusiones/train_faster.png)\n",
    "\n",
    "Perdida de validación.\n",
    "\n",
    "![val_faster](../images/DesarrolloGeneral_Conclusiones/val_faster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpc-ii-2tCthqWZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
