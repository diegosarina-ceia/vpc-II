{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Final Visión por Computadora 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrantes:\n",
    "\n",
    "* Marco Joel Isidro\n",
    "* Diego Sarina\n",
    "\n",
    "Profesores:\n",
    "\n",
    "* Juan Ignacio Cavalieri\n",
    "* Juan Ignacio Cornet\n",
    "* Pakdaman Seyed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema a resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proyecto, abordamos un problema de detección de objetos en imágenes médicas centrado en la identificación de diversas enfermedades dentales. El objetivo principal es automatizar el diagnóstico visual de condiciones dentales comunes como caries, necesidad de endodoncia, o dientes impactados, a partir de imágenes médicas.\n",
    "\n",
    "El interés por resolver este problema radica en la posibilidad de asistir a los profesionales de la odontología en el diagnóstico temprano y preciso, permitiendo la intervención adecuada antes de que las patologías avancen.\n",
    "\n",
    "Para este proyecto, se utilizó un dataset proporcionado por una competencia de Kaggle, lo cual facilitó el acceso a imágenes etiquetadas de radiografías dentales con varias clases de anomalías. La detección de estas condiciones fue tratada como un problema de detección de objetos, donde el modelo debe no solo identificar la presencia de una anomalía, sino también localizar su posición en la imagen.\n",
    "\n",
    "El desafío y datasets propuesto lo pueden encontrar en el siguiente link:\n",
    "\n",
    "[Link al desafía de Kaggle](https://www.kaggle.com/datasets/truthisneverlinear/dentex-challenge-2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de una imágen etiquetada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imágen etiquetada](../images/DesarrolloGeneral_Conclusiones/dataset_inicial.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del datasets inicial del desafio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset utilizado para este proyecto fue inicialmente proporcionado por una competencia en Kaggle y contenía imágenes de radiografías dentales etiquetadas con tres tipos de categorías: cuadrante (donde se encontraba la anomalía), diente (identificación del diente específico afectado) y enfermedad (tipo de patología presente).\n",
    "\n",
    "Sin embargo, para nuestro propósito, que es la detección de enfermedades dentales como caries, necesidad de endodoncia o dientes impactados, las etiquetas relacionadas con los cuadrantes y los dientes específicos no eran relevantes para el problema que queríamos resolver. Por lo tanto, decidimos modificar el dataset eliminando las etiquetas de cuadrante y diente, dejando únicamente las que corresponden a las enfermedades.\n",
    "\n",
    "De esta forma, nuestro modelo se entrenará exclusivamente para identificar y localizar las anomalías dentales en las imágenes, lo que simplifica el problema y nos permite enfocarnos en el objetivo principal del proyecto: la detección automática de enfermedades dentales.\n",
    "\n",
    "A continuación, mostramos un ejemplo de la estructura propuesta en el desafío y la estructura utilizada en el proyecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Estructura propuesta por Dentex\n",
    "{\n",
    "  \"images\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"width\":\n",
    "      \"height\":\n",
    "      \"file_name\":\n",
    "    }\n",
    "  ],\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"image_id\":\n",
    "      \"category_id_1\":\n",
    "      \"category_id_2\":\n",
    "      \"category_id_3\":\n",
    "      \"segmentation\":\n",
    "      \"area\":\n",
    "      \"bbox\":\n",
    "      \"iscrowd\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories_1\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories_2\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories_3\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Estructura utilizada\n",
    "{\n",
    "  \"images\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"width\":\n",
    "      \"height\":\n",
    "      \"file_name\":\n",
    "    }\n",
    "  ],\n",
    "  \"annotations\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"image_id\":\n",
    "      \"category_id\":\n",
    "      \"segmentation\":\n",
    "      \"area\":\n",
    "      \"bbox\":\n",
    "      \"iscrowd\":\n",
    "    }\n",
    "  ],\n",
    "  \"categories\": [\n",
    "    {\n",
    "      \"id\":\n",
    "      \"name\":\n",
    "      \"supercategory\":\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para un análisis más detallado del dataset utilizado pueden acceder al notebook [EDA.ipynb](2_EDA.ipynb) en el sección \"dataset original\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primeros modelos investigados y resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para abordar el problema de detección de objetos de enfermedades dentales, implementamos y entrenamos dos modelos ampliamente utilizados en tareas de detección: RetinaNet y YOLOv8. A continuación, describimos cada modelo brevemente y presentamos los resultados obtenidos en los primeros entrenamientos.\n",
    "\n",
    "RetinaNet es un modelo de detección de objetos que emplea un enfoque de red de \"una etapa\" (one-stage), lo que lo hace más rápido que otros modelos de dos etapas como Faster R-CNN. Su principal característica es la focal loss, una función de pérdida que mitiga el problema del desbalance entre clases, al darle más peso a los ejemplos difíciles (difíciles de clasificar).\n",
    "\n",
    "YOLOv8 es conocida por su velocidad y eficacia en la detección de objetos en tiempo real. YOLOv8 introduce mejoras en la arquitectura y en las técnicas de entrenamiento, lo que lo hace más eficiente que versiones anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los entrenamientos iniciales se llevaron a cabo en los notebooks [3_YOLOv8_training.ipynb](3_YOLOv8_training.ipynb) y [4_RetinaNet_training.ipynb](4_RetinaNet_training.ipynb) en sus secciones de dataset 1 o dataset original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo los entrenamientos con este dataset no mostraron buenos resultados y luego de multiples pruebas se llego a la conclusion de que era problema del etiquetado del dataset. A continuación se resumen los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### YOLOv8:\n",
    "\n",
    "```\n",
    "Model Summary (fused):\n",
    "- **Layers**: 186\n",
    "- **Parameters**: 2,685,148\n",
    "- **Gradients**: 0\n",
    "- **GFLOPs**: 6.8\n",
    "\n",
    "| Class                  | Images | Instances | Box(P) | R    | mAP50 | mAP50-95 |\n",
    "|------------------------|--------|-----------|--------|------|-------|----------|\n",
    "| **all**                | 151    | 709       | 0.467  | 0.564| 0.497 | 0.321    |\n",
    "| **Caries**             | 128    | 447       | 0.351  | 0.620| 0.404 | 0.292    |\n",
    "| **Deep Caries**        | 69     | 126       | 0.464  | 0.579| 0.557 | 0.354    |\n",
    "| **Impacted**           | 48     | 106       | 0.677  | 0.991| 0.956 | 0.604    |\n",
    "| **Periapical Lesion**  | 23     | 30        | 0.377  | 0.067| 0.071 | 0.034    |\n",
    "\n",
    "```\n",
    "\n",
    "Después de entrenar nuestro modelo YOLO para la detección de condiciones dentales, obtuvimos algunos resultados interesantes. Vamos a analizarlos:\n",
    "\n",
    "1. Rendimiento general:\n",
    "Nuestro modelo alcanzó un mAP50 de 0.497, lo que significa que está detectando objetos con una precisión media del 49.7% cuando consideramos un umbral de IoU del 50%. No está mal, pero definitivamente hay espacio para mejorar.\n",
    "\n",
    "2. Precisión y Recall:\n",
    "Obtuvimos una precisión de 0.467 y un recall de 0.564. En términos simples, esto sugiere que nuestro modelo es un poco mejor encontrando condiciones dentales reales (recall) que evitando falsos positivos (precisión).\n",
    "\n",
    "3. Configuración del entrenamiento:\n",
    "Usamos dropout de 0.3, lo cual probablemente ayudó a prevenir el overfitting, especialmente considerando que nuestro dataset no es muy grande.ç\n",
    "\n",
    "4. Áreas de mejora:\n",
    "\n",
    "- Definitivamente necesitamos más imágenes, sobre todo para las clases que el modelo tiene más dificultad en detectar.\n",
    "- Podríamos experimentar con diferentes técnicas de aumento de datos.\n",
    "- Tal vez valdría la pena probar otras arquitecturas de modelos o pesos pre-entrenados diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetinaNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.452\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.257\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.159\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.447\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
    "\n",
    "Evaluation results for bbox: \n",
    "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
    "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
    "| 25.705 | 45.206 | 25.807 |  nan  |  nan  | 25.705 |\n",
    "\n",
    "Per-category bbox AP: \n",
    "| category          | AP     | category    | AP     | category   | AP     |\n",
    "|:------------------|:-------|:------------|:-------|:-----------|:-------|\n",
    "| Caries            | 23.356 | Deep Caries | 23.605 | Impacted   | 49.093 |\n",
    "| Periapical Lesion | 6.765  |             |        |            |        |\n",
    "```\n",
    "\n",
    "*Baja precisión general:* El modelo tiene un AP global de 0.257 y solo alcanza un AP50 de 0.452, lo que indica que las detecciones son inexactas, especialmente cuando se requiere mayor precisión en la localización de las enfermedades.\n",
    "\n",
    "*Rendimiento desigual entre categorías:* El modelo identifica mejor los dientes impactados (AP de 49.09%), pero tiene serias dificultades con otras categorías, como Periapical Lesion, donde el AP es muy bajo (6.77%).\n",
    "\n",
    "*Problemas de detección y localización:* El bajo recall sugiere que el modelo está fallando en detectar muchas anomalías, y la falta de precisión en las cajas delimitadoras podría estar afectada por un desbalance en las clases y un dataset subóptimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problematica encontrada y resolución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los principales desafíos que enfrentamos durante el desarrollo del proyecto fue descubrir que el dataset estaba mal etiquetado. Este problema afectaba directamente el rendimiento de los modelos, ya que muchas imágenes tenían etiquetas que se aplicaban al diente en su totalidad, en lugar de centrarse en la patología específica presente. Esto generaba confusión durante el entrenamiento, lo que resultaba en una baja precisión en las predicciones.\n",
    "\n",
    "Al analizar en detalle las etiquetas del dataset, encontramos varios tipos de errores:\n",
    "\n",
    "Etiquetas superpuestas: Debido a que se etiquetaba el diente completo, en muchas imágenes había etiquetas de diferentes categorías solapadas, dificultando la identificación clara de cada patología.\n",
    "Cajas mal posicionadas: Las cajas delimitadoras (bounding boxes) frecuentemente no coincidían con las áreas donde se encontraban las anomalías, afectando la capacidad del modelo para localizar las enfermedades de forma precisa.\n",
    "A continuación, mostramos ejemplos visuales de imágenes mal etiquetadas, donde se puede observar la discrepancia entre las cajas de detección y las enfermedades presentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiples dientes etiquetados con una sola etiqueta.\n",
    "\n",
    "![Error1](../images/DesarrolloGeneral_Conclusiones/error_1.jpg)\n",
    "\n",
    "Etiquetas superpuestas de diferentes categorías.\n",
    "\n",
    "![Error2](../images/DesarrolloGeneral_Conclusiones/error_2.jpg)\n",
    "\n",
    "Etiquetas superpuestas de la misma categoría y bbox demasiado grandes.\n",
    "\n",
    "![Error3](../images/DesarrolloGeneral_Conclusiones/error_3.jpg)\n",
    "\n",
    "Etiquetas mal puestas.\n",
    "\n",
    "![Error4](../images/DesarrolloGeneral_Conclusiones/error_4.png)\n",
    "\n",
    "Etiquetas mal puestas y superpuestas.\n",
    "\n",
    "![Error5](../images/DesarrolloGeneral_Conclusiones/error_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver este problema, decidimos utilizar una versión revisada del dataset, basada en el trabajo de otro participante del desafío, quien había corregido algunos de los problemas de etiquetado. Esta versión tenía etiquetas más consistentes y precisas, enfocándose en la detección de las patologías en lugar de en el diente completo.\n",
    "\n",
    "Sin embargo, esta versión del dataset no incluía la categoría de diente impactado, una anomalía que queríamos seguir detectando en nuestro proyecto. Por lo tanto, añadimos manualmente la categoría de diente impactado a la nueva versión del dataset, asegurándonos de que las etiquetas y las cajas delimitadoras fueran correctas.\n",
    "\n",
    "La corrección del dataset fue un paso crucial, ya que permitió mejorar significativamente el rendimiento de los modelos al eliminar gran parte de la confusión generada por las etiquetas incorrectas. La calidad de los datos es fundamental para que los modelos de detección de objetos puedan aprender patrones útiles y producir predicciones precisas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos investigados y resultados principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones finales"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
